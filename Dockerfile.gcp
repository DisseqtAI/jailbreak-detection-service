FROM --platform=linux/amd64 python:3.10-slim

# Set working directory
WORKDIR /app

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    TRANSFORMERS_CACHE=/app/models \
    NLTK_DATA=/app/nltk_data \
    PORT=8080

# Install system dependencies - combined in one RUN to reduce layers
RUN apt-get update && \
    apt-get install -y --no-install-recommends gcc && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies - combined in one RUN
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir mangum==0.19.0 && \
    # Setup NLTK data
    python -c "import nltk; nltk.download('punkt', download_dir='/app/nltk_data'); nltk.download('stopwords', download_dir='/app/nltk_data'); nltk.download('wordnet', download_dir='/app/nltk_data')"

# Create model directories
RUN mkdir -p /app/models

# Copy application code
COPY ./app ./app
COPY detector.py .
COPY download_models.py .

# Download models with optimized settings
RUN python download_models.py && \
    # Create a cloud run specific main file
    echo 'import uvicorn\nimport os\nfrom app.app import app\n\nif __name__ == "__main__":\n    port = int(os.environ.get("PORT", 8080))\n    uvicorn.run(app, host="0.0.0.0", port=port)' > main_cloud_run.py

# Expose port
EXPOSE 8080

# Run the application
CMD ["python", "main_cloud_run.py"] 